{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Module 3 -Regression -Beta Calculation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmNCXHJeRPRV",
        "colab_type": "text"
      },
      "source": [
        "##Module 3 -\n",
        "\n",
        "### Solution notebook for module 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T78FlghhALBi",
        "colab_type": "code",
        "outputId": "132e2172-d922-46a5-8e62-fb1cbd665930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NePU-47JRBHs",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Query 3.1 \n",
        "\n",
        "    Import the file 'gold.csv' (you will find this in the intro section to download or in '/Data/gold.csv' if you are using the jupyter notebook), which contains the data of the last 2 years price action of Indian (MCX) gold standard. Explore the dataframe. You'd see 2 unique columns - 'Pred' and 'new'. One of the 2 columns is a linear combination of the OHLC prices with varying coefficients while the other is a polynomial function of the same inputs. Also, one of the 2 columns is partially filled.\n",
        "    \n",
        "    -- Using linear regression, find the coefficients of the inputs and using the same trained model, complete the entire column.\n",
        "    \n",
        "    -- Also, try to fit the other column as well using a new linear regression model. Check if the predictions are accurate. Mention which column is a linear function and which is polynomial.\n",
        "    (Hint: Plotting a histogram & distplot helps in recognizing the discrepencies in prediction, if any.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0-iMNpd6i6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "gold= pd.read_csv('GOLD.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMV3pFE_BOyp",
        "colab_type": "code",
        "outputId": "78a7c584-ccb2-43ad-ebc1-c5bed62e0758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "gold.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Price</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Vol.</th>\n",
              "      <th>Change %</th>\n",
              "      <th>Pred</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>May 04, 2017</td>\n",
              "      <td>28060</td>\n",
              "      <td>28400</td>\n",
              "      <td>28482</td>\n",
              "      <td>28025</td>\n",
              "      <td>0.08K</td>\n",
              "      <td>-1.79%</td>\n",
              "      <td>738.0</td>\n",
              "      <td>117.570740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>May 05, 2017</td>\n",
              "      <td>28184</td>\n",
              "      <td>28136</td>\n",
              "      <td>28382</td>\n",
              "      <td>28135</td>\n",
              "      <td>0.06K</td>\n",
              "      <td>0.44%</td>\n",
              "      <td>-146.0</td>\n",
              "      <td>295.430176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>May 08, 2017</td>\n",
              "      <td>28119</td>\n",
              "      <td>28145</td>\n",
              "      <td>28255</td>\n",
              "      <td>28097</td>\n",
              "      <td>7.85K</td>\n",
              "      <td>-0.23%</td>\n",
              "      <td>30.0</td>\n",
              "      <td>132.123714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>May 09, 2017</td>\n",
              "      <td>27981</td>\n",
              "      <td>28125</td>\n",
              "      <td>28192</td>\n",
              "      <td>27947</td>\n",
              "      <td>10.10K</td>\n",
              "      <td>-0.49%</td>\n",
              "      <td>357.0</td>\n",
              "      <td>101.298064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>May 10, 2017</td>\n",
              "      <td>28007</td>\n",
              "      <td>28060</td>\n",
              "      <td>28146</td>\n",
              "      <td>27981</td>\n",
              "      <td>9.28K</td>\n",
              "      <td>0.09%</td>\n",
              "      <td>124.0</td>\n",
              "      <td>112.153318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date  Price   Open   High    Low    Vol. Change %   Pred         new\n",
              "0  May 04, 2017  28060  28400  28482  28025   0.08K   -1.79%  738.0  117.570740\n",
              "1  May 05, 2017  28184  28136  28382  28135   0.06K    0.44% -146.0  295.430176\n",
              "2  May 08, 2017  28119  28145  28255  28097   7.85K   -0.23%   30.0  132.123714\n",
              "3  May 09, 2017  27981  28125  28192  27947  10.10K   -0.49%  357.0  101.298064\n",
              "4  May 10, 2017  28007  28060  28146  27981   9.28K    0.09%  124.0  112.153318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZS_PXfxSXiU",
        "colab_type": "text"
      },
      "source": [
        "**we can see the columns gold[''Pred] and gold['new'] in the dataframe above.**\n",
        "\n",
        "**To find out which one is partially filled we can use pandas info( ) function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyKNPX8hSuip",
        "colab_type": "code",
        "outputId": "ae210208-2a63-4c53-96e2-9b75c843474f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "gold.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 512 entries, 0 to 511\n",
            "Data columns (total 9 columns):\n",
            "Date        512 non-null object\n",
            "Price       512 non-null int64\n",
            "Open        512 non-null int64\n",
            "High        512 non-null int64\n",
            "Low         512 non-null int64\n",
            "Vol.        512 non-null object\n",
            "Change %    512 non-null object\n",
            "Pred        411 non-null float64\n",
            "new         512 non-null float64\n",
            "dtypes: float64(2), int64(4), object(3)\n",
            "memory usage: 36.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfD3eVe5SyRI",
        "colab_type": "text"
      },
      "source": [
        "**As we can see above that Pred is the column that is partially filled, we can use the filled portion of this column in training data and make rest of it as testing dataset. The prediction on this test set can then be used to fill the entire column.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EJvcvWmAxyk",
        "colab_type": "code",
        "outputId": "e0c51ef6-dba0-4d2f-8740-4a4db34fc561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#to generate the training data by dropping rows with any empty column.\n",
        "gold_train= gold.dropna()\n",
        "\n",
        "#testing data will be generated by taking rows with any empty column.\n",
        "gold_test= gold[pd.isnull(gold).any(axis= 1)]\n",
        "\n",
        "#just to check \n",
        "print('The training data has {} samples, and testing data has {} samples.'.format(len(gold_train), len(gold_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training data has 411 samples, and testing data has 101 samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryQLHqR3T_Ss",
        "colab_type": "text"
      },
      "source": [
        "**We can now take our OHLC (open, high, low and close ) as features and both Pred and new as labels to train our linear regression model on.**\n",
        "\n",
        "**NOTE : the training will be done using the training data we generated earlier.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSKxFqVMB6J9",
        "colab_type": "code",
        "outputId": "48f58f28-7d77-43eb-d7d6-0a57f38398b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#features for our model.\n",
        "X = gold_train.iloc[:, 1: 5].values\n",
        "\n",
        "#our label\n",
        "y = gold_train.iloc[:, 7: 8].values\n",
        "\n",
        "#jsut to check\n",
        "print(\"The features are -- \\n {0}\\n\\nThe labels are -- \\n {1}\".format(gold_train.iloc[:, 1: 5].head(), gold_train.iloc[:, 7: 8].head()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The features are -- \n",
            "    Price   Open   High    Low\n",
            "0  28060  28400  28482  28025\n",
            "1  28184  28136  28382  28135\n",
            "2  28119  28145  28255  28097\n",
            "3  27981  28125  28192  27947\n",
            "4  28007  28060  28146  27981\n",
            "\n",
            "The labels are -- \n",
            "     Pred\n",
            "0  738.0\n",
            "1 -146.0\n",
            "2   30.0\n",
            "3  357.0\n",
            "4  124.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKlFPub8WkL3",
        "colab_type": "text"
      },
      "source": [
        "**So we have set our features to be OHLC and our label is Pred right now.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkdgNZLKWtxi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LMR8OT5MMBW",
        "colab_type": "code",
        "outputId": "78fe61ac-abaf-475e-bf59-ed391bf15ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#splitting data in training and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor_pred = LinearRegression()\n",
        "regressor_pred.fit(X_train, y_train)\n",
        "\n",
        "# check the score on test set, the output is the the probablity for correct prediction.\n",
        "print(\"The accuracy of test set is {}\".format(regressor_pred.score(X_val, y_val) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of test set is 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxK31e2wYPkP",
        "colab_type": "text"
      },
      "source": [
        "**The accuracy on test set is 100, which mean our LINEAR REGRESSION model is able to predict correctly everytime, thus suggesting a linear mapping between inputs and output.**\n",
        "\n",
        "**The result also suggest that Pred is the output, that is linear combination of OHLC input.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doa4Uc-rPFH4",
        "colab_type": "code",
        "outputId": "fbbd71c4-e7c5-4f13-f993-a3f4f4e0434f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#to find the cofficient of the features in trained model.\n",
        "print('The cofficient of the inputs are {}' .format(regressor_pred.coef_))\n",
        "\n",
        "#to find the interceptt of the features in trained model.\n",
        "print('The intercept of the inputs are {}' .format(regressor_pred.intercept_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cofficient of the inputs are [[ 2.  3. -1. -4.]]\n",
            "The intercept of the inputs are [6.03108674e-11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axt_bTKXYONZ",
        "colab_type": "text"
      },
      "source": [
        "**We can see that the cofficients are integer numbers thus for linear equation. Thus suggesting that Pred is infact linear combination of inputs.**\n",
        "\n",
        " **coef_1 * low + coef_2 * high + coef_3 * open + coef_4 * price(close) + intercept = Pred.**\n",
        " \n",
        " **The next task would be to complete the entire column using the same trained model, we will use regressor_pred as that was the column that had empty rows.**\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbyLW-n9fPLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict the values of Pred for all empty column using gold_test column used earlier.\n",
        "Pred= regressor_pred.predict(gold_test.iloc[:, 1: 5].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbRMO7R_faCm",
        "colab_type": "code",
        "outputId": "c81d81fd-6f0a-496d-8163-bc1a8bdc8df1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#update the rows in gold_test\n",
        "gold_test['Pred']= Pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TIN8nKgfgXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#append gold_test to out original data.\n",
        "gold [ 411 : ]= gold_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoyfe-kbfhHp",
        "colab_type": "code",
        "outputId": "34edf2f5-bd26-4bf6-d0b6-fab5a0416ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "gold.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Pred</th>\n",
              "      <th>new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>512.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>512.000000</td>\n",
              "      <td>512.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>30364.583984</td>\n",
              "      <td>30368.412109</td>\n",
              "      <td>30491.089844</td>\n",
              "      <td>30243.320312</td>\n",
              "      <td>370.033203</td>\n",
              "      <td>245.161859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1284.378623</td>\n",
              "      <td>1296.856656</td>\n",
              "      <td>1307.031684</td>\n",
              "      <td>1271.936410</td>\n",
              "      <td>341.296591</td>\n",
              "      <td>205.788897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>27812.000000</td>\n",
              "      <td>27805.000000</td>\n",
              "      <td>27887.000000</td>\n",
              "      <td>27620.000000</td>\n",
              "      <td>-146.000000</td>\n",
              "      <td>11.109814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>29432.500000</td>\n",
              "      <td>29436.750000</td>\n",
              "      <td>29499.750000</td>\n",
              "      <td>29345.750000</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>101.369172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>30427.500000</td>\n",
              "      <td>30399.500000</td>\n",
              "      <td>30545.000000</td>\n",
              "      <td>30286.000000</td>\n",
              "      <td>322.000000</td>\n",
              "      <td>184.537244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>31271.750000</td>\n",
              "      <td>31300.000000</td>\n",
              "      <td>31447.500000</td>\n",
              "      <td>31160.750000</td>\n",
              "      <td>495.000000</td>\n",
              "      <td>320.835031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>33753.000000</td>\n",
              "      <td>34247.000000</td>\n",
              "      <td>34400.000000</td>\n",
              "      <td>33680.000000</td>\n",
              "      <td>3024.000000</td>\n",
              "      <td>1407.321485</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Price          Open  ...         Pred          new\n",
              "count    512.000000    512.000000  ...   512.000000   512.000000\n",
              "mean   30364.583984  30368.412109  ...   370.033203   245.161859\n",
              "std     1284.378623   1296.856656  ...   341.296591   205.788897\n",
              "min    27812.000000  27805.000000  ...  -146.000000    11.109814\n",
              "25%    29432.500000  29436.750000  ...   164.000000   101.369172\n",
              "50%    30427.500000  30399.500000  ...   322.000000   184.537244\n",
              "75%    31271.750000  31300.000000  ...   495.000000   320.835031\n",
              "max    33753.000000  34247.000000  ...  3024.000000  1407.321485\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qyqr-ZX_fn_A",
        "colab_type": "text"
      },
      "source": [
        "**We have found correct value of Pred for all the empty rows and updated our dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaHlRGp3Zz8n",
        "colab_type": "text"
      },
      "source": [
        "**Our next step would be to set new column as a output and find if we have a linear mapping from inputs to output.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLvvbUWaR5t",
        "colab_type": "code",
        "outputId": "cd63d4fe-7ee4-455b-bfe7-a0d1db15758d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "#features for our model.\n",
        "X = gold_train.iloc[:, 1: 5].values\n",
        "\n",
        "#our label\n",
        "y = gold_train.iloc[:, 8 : ].values\n",
        "\n",
        "#jsut to check\n",
        "print(\"The features are -- \\n {0}\\n\\nThe labels are -- \\n {1}\".format(gold_train.iloc[:, 1: 5].head(), gold_train.iloc[:, 8: ].head()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The features are -- \n",
            "    Price   Open   High    Low\n",
            "0  28060  28400  28482  28025\n",
            "1  28184  28136  28382  28135\n",
            "2  28119  28145  28255  28097\n",
            "3  27981  28125  28192  27947\n",
            "4  28007  28060  28146  27981\n",
            "\n",
            "The labels are -- \n",
            "           new\n",
            "0  117.570740\n",
            "1  295.430176\n",
            "2  132.123714\n",
            "3  101.298064\n",
            "4  112.153318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7ubDCTBRK40",
        "colab_type": "code",
        "outputId": "a8bd3efa-e7ad-4f33-9be1-cc1468626b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#splitting data in training and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor_new = LinearRegression()\n",
        "regressor_new.fit(X_train, y_train)\n",
        "\n",
        "# check the score on test set, the output is the the probablity for correct prediction.\n",
        "print(\"The accuracy of test set is {}\".format(regressor_new.score(X_val, y_val) * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of test set is 99.99924790346442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyqxyD2gacR4",
        "colab_type": "text"
      },
      "source": [
        "**The accuracy on test set is 99.99.. , which mean our LINEAR REGRESSION model is able to predict correctly ALMOST everytime, however this drop in accuracy suggest that there are some higher powers involved in our equation. Thus this mapping is NOT strictly LINEAR**\n",
        "\n",
        "**The result also suggest that new is the output, that is NOT a linear combination of OHLC input.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0HCWKFnbhkk",
        "colab_type": "code",
        "outputId": "930d17e5-2c44-4458-b987-de4131ab5718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#to find the cofficient of the features in trained model.\n",
        "print('The cofficient of the inputs are {}' .format(regressor_new.coef_))\n",
        "\n",
        "#to find the cofficient of the features in trained model.\n",
        "print('The cofficient of the inputs are {}' .format(regressor_new.intercept_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cofficient of the inputs are [[ 1.01216926 -1.00112185  1.00522654 -1.01630605]]\n",
            "The cofficient of the inputs are [-0.41905518]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSSqfs_6bnFc",
        "colab_type": "text"
      },
      "source": [
        "**We can see that the cofficients are floating point numbers. Thus suggesting that new is not a linear combination of inputs.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwjNADu_axex",
        "colab_type": "code",
        "outputId": "a40551dd-b5fe-4bfe-fa4a-a6199b1e5750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(gold['Pred'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1aaabf8a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nptdYq3kZ7gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUkpW86DhIjj",
        "colab_type": "code",
        "outputId": "6c495f24-0ff3-4bb8-8e51-01c605cb5021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "sns.distplot(gold['new'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1aaaafb8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEKCAYAAAAMzhLIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbQbLUv5heQe",
        "colab_type": "text"
      },
      "source": [
        "**The distplot also suggest that the the data points are evenly distributed in case of Pred, and somewhat skewed in case of new, thus suggesting that the predictions in case of Pred are infact more accurate than in case of new.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUx-FS5Bdy4o",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##Query3.2 \n",
        "    Import the stock of your choosing AND the Nifty index. \n",
        "    \n",
        "    Using linear regression (OLS), calculate -\n",
        "    -- The daily Beta value for the past 3 months. (Daily= Daily returns)\n",
        "    -- The monthly Beta value. (Monthly= Monthly returns)\n",
        "    \n",
        "    \n",
        "    Refrain from using the (covariance(x,y)/variance(x)) formula. \n",
        "    \n",
        "    Attempt the question using regression.(Regression Reference) \n",
        "    Were the Beta values more or less than 1 ? What if it was negative ? \n",
        "    Discuss. Include a brief writeup in the bottom of your jupyter notebook with your inferences from the Beta values and regression results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R_qNnG2MP94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import the datasets\n",
        "Laxmi= pd.read_csv('LAXMIMACH.csv')\n",
        "nifty50= pd.read_csv('Nifty50.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p1XmfFje-w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Laxmi_3_mo= Laxmi[:][432 : 494]\n",
        "nifty50_3_mo= nifty50[:][432 : 494]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyn-zwCp9Gxa",
        "colab_type": "text"
      },
      "source": [
        "**We will get data for last 3 months, on average a quarter is taken to be 63 days longer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef18DYhSxD7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "daily_prices = pd.concat([Laxmi_3_mo['Close Price'], nifty50_3_mo['Close']], axis=1)\n",
        "daily_prices.columns = ['Laxmi', 'nifty50']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVXSN1v-90_-",
        "colab_type": "text"
      },
      "source": [
        "**We will create a new dataframe called daily_prices with closing prices of LAXMIMACH and our index that is, Nifty50.**\n",
        "\n",
        "**The next step would be to calculate the daily percentage changes for both the columns and drop all NaN from our updated dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcRJahvUgwQL",
        "colab_type": "code",
        "outputId": "5d86078e-9428-44f0-8064-363af4d8f919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "daily_returns = daily_prices.pct_change(1)\n",
        "clean_daily_returns = daily_returns.dropna(axis=0)  # drop first missing row\n",
        "print(clean_daily_returns.head(10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Laxmi   nifty50\n",
            "433 -0.006529 -0.011365\n",
            "434 -0.007550 -0.005007\n",
            "435 -0.015285 -0.005271\n",
            "436 -0.001460 -0.003485\n",
            "437  0.001751 -0.004410\n",
            "438 -0.016076 -0.002015\n",
            "439 -0.012447 -0.007781\n",
            "440  0.003728 -0.003440\n",
            "441  0.000231  0.012363\n",
            "442  0.008970  0.005067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJshKTXm-Q-i",
        "colab_type": "text"
      },
      "source": [
        "**Good! Now that we have a clean set of daily returns on LAXMIMACH and Nifty 50. Let’s go ahead and make the Ordinary Least Square (OLS)Regression with Statsmodels.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFtpPDh6g5ub",
        "colab_type": "code",
        "outputId": "ca371622-d816-4d9c-f973-2e12925f4ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "import statsmodels.api as sm\n",
        "# split dependent and independent variable\n",
        "X = clean_daily_returns['nifty50']\n",
        "y = clean_daily_returns['Laxmi']\n",
        "\n",
        "# Add a constant to the independent value\n",
        "X1 = sm.add_constant(X)\n",
        "\n",
        "# make regression model \n",
        "model = sm.OLS(y, X1)\n",
        "\n",
        "# fit model and print results\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Laxmi   R-squared:                       0.157\n",
            "Model:                            OLS   Adj. R-squared:                  0.142\n",
            "Method:                 Least Squares   F-statistic:                     10.95\n",
            "Date:                Fri, 12 Jul 2019   Prob (F-statistic):            0.00160\n",
            "Time:                        05:41:25   Log-Likelihood:                 191.61\n",
            "No. Observations:                  61   AIC:                            -379.2\n",
            "Df Residuals:                      59   BIC:                            -375.0\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.0008      0.001     -0.621      0.537      -0.004       0.002\n",
            "nifty50        0.6544      0.198      3.309      0.002       0.259       1.050\n",
            "==============================================================================\n",
            "Omnibus:                       18.994   Durbin-Watson:                   1.467\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               24.425\n",
            "Skew:                           1.263   Prob(JB):                     4.97e-06\n",
            "Kurtosis:                       4.796   Cond. No.                         145.\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCYUcTVDr9Wa",
        "colab_type": "code",
        "outputId": "c005f49d-e1e5-4a22-81b3-f4ba8346fbb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# alternatively scipy linear regression\n",
        "from scipy import stats\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(X, y)\n",
        "\n",
        "#the slope of the regression lines denotes the beta.\n",
        "print(slope)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6543587998923448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrhCJz5Yna8j",
        "colab_type": "text"
      },
      "source": [
        "###Interpretation of a Beta result\n",
        "\n",
        "    A stock with a beta of:\n",
        "    -> zero indicates no correlation with the chosen benchmark (e.g. NASDAQ index )\n",
        "    -> one indicates a stock has the same volatility as the market\n",
        "    -> more than one indicates a stock that’s more volatile than its benchmark\n",
        "    -> less than one is less volatile than the benchmark\n",
        "    -> 1.5 is 50% more volatile than the benchmark\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOVpR_aWnuGk",
        "colab_type": "text"
      },
      "source": [
        "**Thus value of beta is 0.6544, As you can see from the summary, the coefficient value for (LAXMIMACH) is 0.6544. This suggest that the Laxmimach have be LESS volatile than Nifty 50 over the course of last 3 months.**\n",
        "\n",
        "**In this method, we regress the company’s stock returns against the market’s returns. The beta (β) is represented by the slope of the regression line.**\n",
        "\n",
        " **stock_return= 0.6543 * market_return + (- 0.0008)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpWZrmxq-dzI",
        "colab_type": "text"
      },
      "source": [
        "**Next step would be to do the same for monthly beta values, that is to find out the beta values monthly returns for last 3 years.**\n",
        "\n",
        "**We would group both our datasets by months and years, to get monthly closing prices for both the data sets and calculate monthly percentage change.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqrMmKPEt88L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Laxmi['Date']= pd.to_datetime(Laxmi['Date'])\n",
        "\n",
        "nifty50['Date']= pd.to_datetime(nifty50['Date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LfSBl0NvZWb",
        "colab_type": "code",
        "outputId": "994a7318-57a0-45ba-a618-12e3711348cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#initialize a new column and provide 0 value to each of its row.\n",
        "Laxmi['month']= 0\n",
        "\n",
        "#now for entire length of data we would replce the 0 with month value\n",
        "#we can get month value from data['Date']\n",
        "for i in range (0, 494):\n",
        "  Laxmi['month'][i]= Laxmi['Date'][i].month"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uMCLSkGxQxj",
        "colab_type": "code",
        "outputId": "7727b71c-2515-436e-8164-9510df568781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#initialize a new column and provide 0 value to each of its row.\n",
        "nifty50['month']= 0\n",
        "\n",
        "#now for entire length of data we would replce the 0 with month value\n",
        "#we can get month value from data['Date']\n",
        "for i in range (0, 494):\n",
        "  nifty50['month'][i]= nifty50['Date'][i].month"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FrP_bNiwDbr",
        "colab_type": "code",
        "outputId": "7ce48d0a-e55b-4410-e8d6-609aa00f09d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#initialize a new column and provide 0 value to each of its row.\n",
        "Laxmi['year']= 0\n",
        "\n",
        "#now for entire length of data we would replce the 0 with month value\n",
        "#we can get month value from data['Date']\n",
        "for i in range (0, 494):\n",
        "  Laxmi['year'][i]= Laxmi['Date'][i].year"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOyqYwV8xtyd",
        "colab_type": "code",
        "outputId": "4da72b10-ac4d-4b34-8bf6-83b4305c43dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#initialize a new column and provide 0 value to each of its row.\n",
        "nifty50['year']= 0\n",
        "\n",
        "#now for entire length of data we would replce the 0 with month value\n",
        "#we can get month value from data['Date']\n",
        "for i in range (0, 494):\n",
        "  nifty50['year'][i]= nifty50['Date'][i].year"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeElNVsxvlm9",
        "colab_type": "code",
        "outputId": "7d4c3d0f-aa53-427e-a7c5-102e36ecbc69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "Laxmi.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Series</th>\n",
              "      <th>Date</th>\n",
              "      <th>Prev Close</th>\n",
              "      <th>Open Price</th>\n",
              "      <th>High Price</th>\n",
              "      <th>Low Price</th>\n",
              "      <th>Last Price</th>\n",
              "      <th>Close Price</th>\n",
              "      <th>Average Price</th>\n",
              "      <th>Total Traded Quantity</th>\n",
              "      <th>Turnover</th>\n",
              "      <th>No. of Trades</th>\n",
              "      <th>Deliverable Qty</th>\n",
              "      <th>% Dly Qt to Traded Qty</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LAXMIMACH</td>\n",
              "      <td>EQ</td>\n",
              "      <td>2017-05-15</td>\n",
              "      <td>4552.40</td>\n",
              "      <td>4619.95</td>\n",
              "      <td>4670.0</td>\n",
              "      <td>4550.05</td>\n",
              "      <td>4606.0</td>\n",
              "      <td>4614.05</td>\n",
              "      <td>4629.76</td>\n",
              "      <td>4275</td>\n",
              "      <td>19792243.95</td>\n",
              "      <td>1097</td>\n",
              "      <td>2447</td>\n",
              "      <td>57.24</td>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LAXMIMACH</td>\n",
              "      <td>EQ</td>\n",
              "      <td>2017-05-16</td>\n",
              "      <td>4614.05</td>\n",
              "      <td>4566.05</td>\n",
              "      <td>4650.0</td>\n",
              "      <td>4564.10</td>\n",
              "      <td>4582.0</td>\n",
              "      <td>4589.80</td>\n",
              "      <td>4612.18</td>\n",
              "      <td>4467</td>\n",
              "      <td>20602592.70</td>\n",
              "      <td>805</td>\n",
              "      <td>2961</td>\n",
              "      <td>66.29</td>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LAXMIMACH</td>\n",
              "      <td>EQ</td>\n",
              "      <td>2017-05-17</td>\n",
              "      <td>4589.80</td>\n",
              "      <td>4500.00</td>\n",
              "      <td>4675.2</td>\n",
              "      <td>4500.00</td>\n",
              "      <td>4610.0</td>\n",
              "      <td>4637.25</td>\n",
              "      <td>4608.88</td>\n",
              "      <td>6320</td>\n",
              "      <td>29128119.85</td>\n",
              "      <td>1035</td>\n",
              "      <td>2876</td>\n",
              "      <td>45.51</td>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LAXMIMACH</td>\n",
              "      <td>EQ</td>\n",
              "      <td>2017-05-18</td>\n",
              "      <td>4637.25</td>\n",
              "      <td>4599.95</td>\n",
              "      <td>4624.8</td>\n",
              "      <td>4515.10</td>\n",
              "      <td>4515.1</td>\n",
              "      <td>4544.45</td>\n",
              "      <td>4567.74</td>\n",
              "      <td>4500</td>\n",
              "      <td>20554835.90</td>\n",
              "      <td>831</td>\n",
              "      <td>2776</td>\n",
              "      <td>61.69</td>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LAXMIMACH</td>\n",
              "      <td>EQ</td>\n",
              "      <td>2017-05-19</td>\n",
              "      <td>4544.45</td>\n",
              "      <td>4586.90</td>\n",
              "      <td>4648.0</td>\n",
              "      <td>4490.00</td>\n",
              "      <td>4521.0</td>\n",
              "      <td>4522.70</td>\n",
              "      <td>4556.21</td>\n",
              "      <td>4190</td>\n",
              "      <td>19090528.50</td>\n",
              "      <td>990</td>\n",
              "      <td>1944</td>\n",
              "      <td>46.40</td>\n",
              "      <td>5</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Symbol Series       Date  ...  % Dly Qt to Traded Qty  month  year\n",
              "0  LAXMIMACH     EQ 2017-05-15  ...                   57.24      5  2017\n",
              "1  LAXMIMACH     EQ 2017-05-16  ...                   66.29      5  2017\n",
              "2  LAXMIMACH     EQ 2017-05-17  ...                   45.51      5  2017\n",
              "3  LAXMIMACH     EQ 2017-05-18  ...                   61.69      5  2017\n",
              "4  LAXMIMACH     EQ 2017-05-19  ...                   46.40      5  2017\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKpawbFivtaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to group both the datasets by months and years.\n",
        "Laxmi=Laxmi.groupby([(Laxmi['year']),(Laxmi['month'])]).sum()\n",
        "\n",
        "nifty50=nifty50.groupby([(nifty50['year']),(nifty50['month'])]).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nBk4lahv2pL",
        "colab_type": "code",
        "outputId": "8e74e7c5-d008-428a-a131-8bd5540400b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "nifty50.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Shares Traded</th>\n",
              "      <th>Turnover (Rs. Cr)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">2017</th>\n",
              "      <th>5</th>\n",
              "      <td>123350.50</td>\n",
              "      <td>123923.35</td>\n",
              "      <td>122926.70</td>\n",
              "      <td>123481.25</td>\n",
              "      <td>3033425674</td>\n",
              "      <td>152111.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>202049.90</td>\n",
              "      <td>202510.25</td>\n",
              "      <td>201219.75</td>\n",
              "      <td>201746.05</td>\n",
              "      <td>3667933334</td>\n",
              "      <td>194462.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>206712.80</td>\n",
              "      <td>207362.90</td>\n",
              "      <td>205982.35</td>\n",
              "      <td>206852.50</td>\n",
              "      <td>3849451776</td>\n",
              "      <td>208783.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>208332.50</td>\n",
              "      <td>208864.70</td>\n",
              "      <td>207149.85</td>\n",
              "      <td>207924.85</td>\n",
              "      <td>4296596163</td>\n",
              "      <td>223540.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>209966.65</td>\n",
              "      <td>210486.50</td>\n",
              "      <td>208772.15</td>\n",
              "      <td>209536.25</td>\n",
              "      <td>4294085247</td>\n",
              "      <td>218201.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Open       High  ...  Shares Traded  Turnover (Rs. Cr)\n",
              "year month                        ...                                  \n",
              "2017 5      123350.50  123923.35  ...     3033425674          152111.08\n",
              "     6      202049.90  202510.25  ...     3667933334          194462.80\n",
              "     7      206712.80  207362.90  ...     3849451776          208783.83\n",
              "     8      208332.50  208864.70  ...     4296596163          223540.74\n",
              "     9      209966.65  210486.50  ...     4294085247          218201.28\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85K_O8TMpcfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make a new dataframe with closing prices for both the datasets.\n",
        "monthly_prices = pd.concat([Laxmi['Close Price'], nifty50['Close']], axis=1)\n",
        "monthly_prices.columns = ['Laxmi', 'nifty50']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly4ACZb-qNlo",
        "colab_type": "code",
        "outputId": "1a360aed-17d0-4b12-8ab6-22dc144bcc7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "monthly_prices.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Laxmi</th>\n",
              "      <th>nifty50</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">2017</th>\n",
              "      <th>5</th>\n",
              "      <td>58758.95</td>\n",
              "      <td>123481.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>106507.35</td>\n",
              "      <td>201746.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>113280.40</td>\n",
              "      <td>206852.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>125756.05</td>\n",
              "      <td>207924.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>124913.60</td>\n",
              "      <td>209536.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Laxmi    nifty50\n",
              "year month                      \n",
              "2017 5       58758.95  123481.25\n",
              "     6      106507.35  201746.05\n",
              "     7      113280.40  206852.50\n",
              "     8      125756.05  207924.85\n",
              "     9      124913.60  209536.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWOWFSZB0UJy",
        "colab_type": "code",
        "outputId": "93bb8cf6-153a-43ed-cb9f-a5c13cd5674f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#calculate percentage changes in monthly prices for both the datasets.\n",
        "#don't forget to drop all the null values from the new dataframe.\n",
        "monthly_returns = monthly_prices.pct_change(1)\n",
        "clean_monthly_returns = monthly_returns.dropna(axis=0) *100  # drop first missing row\n",
        "print(clean_monthly_returns.head(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                Laxmi    nifty50\n",
            "year month                      \n",
            "2017 6      81.261493  63.381930\n",
            "     7       6.359232   2.531128\n",
            "     8      11.013070   0.518413\n",
            "     9      -0.669908   0.774992\n",
            "     10     -6.279500  -3.227461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIHzmADb_kZU",
        "colab_type": "text"
      },
      "source": [
        "**Good! Now that we have a clean set of monthly returns on LAXMIMACH and Nifty 50. Let’s go ahead and make the Ordinary Least Square (OLS)Regression with Statsmodels.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07VXi2xz0juj",
        "colab_type": "code",
        "outputId": "6b93c786-96af-47c1-c5f4-3a5cdc295dd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "import statsmodels.api as sm\n",
        "# split dependent and independent variable\n",
        "X = clean_monthly_returns['nifty50']\n",
        "y = clean_monthly_returns['Laxmi']\n",
        "\n",
        "# Add a constant to the independent value\n",
        "X1 = sm.add_constant(X)\n",
        "\n",
        "# make regression model \n",
        "model = sm.OLS(y, X1)\n",
        "\n",
        "# fit model and print results\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Laxmi   R-squared:                       0.916\n",
            "Model:                            OLS   Adj. R-squared:                  0.912\n",
            "Method:                 Least Squares   F-statistic:                     238.5\n",
            "Date:                Fri, 12 Jul 2019   Prob (F-statistic):           2.74e-13\n",
            "Time:                        05:45:16   Log-Likelihood:                -80.383\n",
            "No. Observations:                  24   AIC:                             164.8\n",
            "Df Residuals:                      22   BIC:                             167.1\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.7036      1.471      0.478      0.637      -2.347       3.754\n",
            "nifty50        1.1618      0.075     15.442      0.000       1.006       1.318\n",
            "==============================================================================\n",
            "Omnibus:                        1.485   Durbin-Watson:                   1.268\n",
            "Prob(Omnibus):                  0.476   Jarque-Bera (JB):                1.100\n",
            "Skew:                           0.271   Prob(JB):                        0.577\n",
            "Kurtosis:                       2.102   Cond. No.                         19.6\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
            "  return ptp(axis=axis, out=out, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK_fEql404fe",
        "colab_type": "code",
        "outputId": "8cf4fa67-ae25-4c28-8693-197c22e6ac99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# alternatively scipy linear regression\n",
        "from scipy import stats\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(X, y)\n",
        "\n",
        "print(slope)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1617715669800723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3kM5V4topeQ",
        "colab_type": "text"
      },
      "source": [
        "**As you can see from the summary, the coefficient value for (LAXMIMACH) is 1.1635, which is also confirmed by the slope of our linear mapping.**\n",
        "\n",
        "**Thus we can infer that our beta value for our monthly returns over the last 3 years is greater than 1, thus suggesting thet our stock i.e. LAXMIMACH is MORE volatile than it's benchmark i.e. Nifty 50.**\n",
        "\n",
        "**In this method, we regress the company’s stock returns against the market’s returns. The beta (β) is represented by the slope of the regression line.**\n",
        "\n",
        " **stock_return= 1.1617 * market_return + (0.7036)**\n",
        " \n",
        "**High-beta stocks are supposed to be riskier but provide a potential for higher returns; low-beta stocks pose less risk but also lower returns, we can understand that for last 3 months our stocks is infact less volatile than market index, we can confirm this by seeing the trend in our stocks for last 3 months, but over the last 3 years our stock has shown higher volitality over the monthly returns and thus offer high returns at the cost of high risk.**"
      ]
    }
  ]
}